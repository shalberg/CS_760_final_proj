\relax 
\providecommand\zref@newlabel[2]{}
\citation{metropolitan1959new}
\citation{freedmanValidityBMIIndicator2009}
\citation{nuttallBodyMassIndex2015}
\citation{hulsenBigDataPrecision2019}
\citation{langarizadehApplyingNaiveBayesian2016}
\citation{goncalvesArtificialIntelligenceEarly2022}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Dataset}{1}{}\protected@file@percent }
\citation{quinlanInductionDecisionTrees1986}
\citation{nortonGeneratingBetterDecision1989}
\@writefile{toc}{\contentsline {section}{\numberline {3}Approach}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{4}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Naive Bayes classifier results. a) Histograms of the VAT area feature are show. The solid lines indicate the distribution inferred by the Bayes Classifier. In the left plot, the estimated distribution of alive and dead patients using a normal distribution is very similar. The right plot demonstrates that the learned Gamma distributions better fit the data. b) t-SNE projections of the CT with clinical data and conditions is shown. Patients are colored by their survival or predicted survival using random forest regression Patients predicted to have died (red) are localized in regions in which many patients actually die, indicating the classifier is correctly identify at risk patients are shown for the CT with clinical data and condition indicators dataset. c) The classification recall and accuracy for predicting the clinical conditions of Alzheimer's, cancer, death, diabetes, and heart disease for all three datasets. The models perform optimally when trained with the Gamma distributions and when the clinical data is used in combination with CT. Performance is only slightly enhanced when the additional condition indicators are added.}}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusions and Future Work}{5}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Random Forest classifier results. a) t-SNE projections of the CT with clinical data and conditions is shown. Patients are colored by their survival or predicted survival using random forest regression Patients predicted to have died (red) are localized in regions in which many patients actually die, indicating the classifier is correctly identify at risk patients are shown for the CT with clinical data and condition indicators dataset. The regions or predicted death are more closely associated with actual regions of predicted death than with the Bayes classifier. c) The classification recall and accuracy for predicting the clinical conditions of Alzheimer's, cancer, death, diabetes, and heart disease for all three datasets. The random forest model drastically improves with the addition of clinical data and condition indicators. For comparison, a random forest model without pruning and pruning is shown. Pruning decreases both recall and accuracy.}}{6}{}\protected@file@percent }
\bibstyle{abbrv}
\bibdata{CS_Final_report}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Age and Biological Age Predictions. The top left plot shows actual ages, Regions of the t-SNE related to death have slightly elevated ages. The LOWESS method increase the contrast between regions and ages. The regions of t-SNE related to death have much higher ages than the corresponding actual ages. Both KNN methods (unweighted and weighted) show elevation in ages in areas associated with death but to a far lesser extent than the LOWESS. }}{7}{}\protected@file@percent }
\bibcite{metropolitan1959new}{1}
\bibcite{freedmanValidityBMIIndicator2009}{2}
\bibcite{goncalvesArtificialIntelligenceEarly2022}{3}
\bibcite{hulsenBigDataPrecision2019}{4}
\bibcite{langarizadehApplyingNaiveBayesian2016}{5}
\bibcite{nortonGeneratingBetterDecision1989}{6}
\bibcite{nuttallBodyMassIndex2015}{7}
\bibcite{quinlanInductionDecisionTrees1986}{8}
\@writefile{toc}{\contentsline {section}{\numberline {6}References}{8}{}\protected@file@percent }
\gdef \@abspage@last{8}
